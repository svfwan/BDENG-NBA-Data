{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NBA Analysis: A Comparison of Michael Jordan, Kobe Bryant and LeBron James at Their Prime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "![LebronKobeMJ](./images/KobeMJLebron.png)\n",
    "\n",
    "Our project focuses on the age old discussion: Who was the best basketball player at their best? Michael Jordan, Kobe Bryant and LeBron James are widely considered the best basketball players of all time and are usually ranked on preference, but by examining the statistics at their arguable prime years, we seek to gain insights and compare their achievements on the basketball court. The results will be based purely on statistics and official achievements. Furthermore, we orchestrated this data science project in a way which focuses on the use of standardised tools and multiple data sources in regards to Big Data and Big Data Engineering requirements. The challenge is to combine all these and create a valuable insight with the collected and processed data.\n",
    "\n",
    "Our team consists of following members:\n",
    "\n",
    "- Maria Mirnic (wi21b105)\n",
    "- Kevin Xhunga (wi21b025)\n",
    "- Safwan Zullash (wi21b030)\n",
    "\n",
    "You can find the whole project in this [GitHub Repo](https://github.com/wi21b030/BDENG-NBA-Data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Requirements Overview\n",
    "\n",
    "| Requirement                                      | Description                                                                                                                                                  |\n",
    "|-------------------------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
    "| At least 3 different data sources of different data types | The project should utilize a minimum of three data sources that offer diverse data types, such as APIs, web scraping, and CSV files.                                |\n",
    "| Use Kafka to collect the data                    | Kafka should be employed as a central message broker to collect data from various sources. It acts as a scalable and fault-tolerant system for data ingestion.  |\n",
    "| Use Spark to read data from Kafka and analyze it | Spark, as the core processing framework, should be used to read data from Kafka and perform data manipulation and analysis tasks efficiently.                      |\n",
    "| Store analyzed/transformed data/results          | The project should store the analyzed and transformed data in a suitable database or file format to ensure data persistence and enable further analysis or retrieval. |\n",
    "| Show results and tell a story                    | The project should present the analysis results through visualizations and storytelling to effectively communicate insights derived from the data.                  |\n",
    "| Visualize the architecture of the system         | The project should provide a graphical representation of the architecture, illustrating the flow of data and the components involved in data processing.            |\n",
    "| Document each step in a Jupyter notebook         | Each step of the project should be thoroughly documented in Jupyter notebooks, providing transparency, reproducibility, and clear explanations of the process.   |\n",
    "| Infrastructure must be multiuser capable         | The project infrastructure should support multiple users, allowing for concurrent collaboration and efficient development and maintenance of the project.         |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup and Solution Architecture\n",
    "\n",
    "![Architecture](./images/Architecture.jpg)\n",
    "\n",
    "### Architecture:\n",
    "\n",
    "Our project architecture is designed to handle the data processing and analysis tasks in a distributed and scalable manner. The architecture consists of several key components that work together to ensure efficient data ingestion, processing, and storage.\n",
    "\n",
    "- **Data Sources**: We leverage multiple data sources to gather a comprehensive dataset for analysis. These sources include REST-APIs, web data obtained through web scraping, and structured data from CSV files. By incorporating different data types and sources, we enrich our analysis and gain a holistic view of the basketball players' performances.\n",
    "\n",
    "- **Kafka**: Kafka plays a central role in our architecture as a message broker. It acts as a data pipeline, collecting data from various sources using Kafka producers and storing it in Kafka topics. This decouples the data producers from the consumers, enabling efficient data ingestion and processing. With Kafka, we ensure fault tolerance, scalability, and real-time data streaming capabilities.\n",
    "\n",
    "- **Spark**: Spark serves as the core processing framework in our architecture. It is responsible for reading data from Kafka using Kafka consumers and performing various data manipulation and analysis tasks using Spark DataFrames. Spark's distributed computing capabilities allow us to handle large-scale data processing, ensuring high-performance analytics.\n",
    "\n",
    "- **Pandas**: We incorporate the use of Pandas, a popular Python library, for data cleaning and visualizations. Pandas offers extensive data processing capabilities and interoperability with Spark, making it a valuable tool for tasks such as data cleaning and creating visualizations. Its familiar syntax and versatility allow our team to work efficiently with the data.\n",
    "\n",
    "- **Database (MongoDB)**: To store the analyzed and transformed data, we utilize a MongoDB database. MongoDB is a NoSQL document-based database that offers flexibility and scalability, making it suitable for handling large volumes of data. Storing the data in MongoDB allows for easy retrieval, querying, and further analysis.\n",
    "\n",
    "- **Jupyter Lab**: Our project environment revolves around Jupyter Lab, which provides an interactive development environment for executing code and maintaining the project. Jupyter Lab offers a range of features, including support for multiple programming languages, interactive notebooks, and a flexible interface that enhances productivity and collaboration.\n",
    "\n",
    "- **GitHub**: We adopt GitHub as our version control system to manage code, track changes, and facilitate collaborative development. GitHub ensures that all project members have access to the latest code and can work concurrently on different project components. It allows for efficient code merging, branching, and version control, promoting effective collaboration and project management.\n",
    "   \n",
    "### Software Components and Versions\n",
    "\n",
    "Here are the Python Packages we used and additional software that helped us during the project:\n",
    "\n",
    "| Packages/Software   | Version       |\n",
    "|---------------------|---------------|\n",
    "| PySpark             | 3.3.2         |\n",
    "| Kafka-Python        | 2.0.2         |\n",
    "| PyMongo             | 4.3.3         |\n",
    "| Pandas              | 1.5.3         |\n",
    "| NumPy               | 1.23.5        |\n",
    "| Matplotlib          | 3.7.1         |\n",
    "| Seaborn             | 0.12.2        |\n",
    "| Python              | 3.10.10       |\n",
    "| MongoDB Compass     | 1.37.0        |\n",
    "\n",
    "If you need to install the packages by yourself here are the commands that you can copy and run in your JupyterLab environment:\n",
    "```python\n",
    "!pip install pyspark\n",
    "!pip install kafka-python\n",
    "!pip install pymongo\n",
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "We used three different data sources:\n",
    "\n",
    "- \"Ball Don't Lie\" API - [Link](\"https://www.balldontlie.io/home.html#introduction\")\n",
    "- CSV-Data from Kaggle - [Link](\"https://www.kaggle.com/datasets/drgilermo/nba-players-stats?select=Seasons_Stats.csv\")\n",
    "- NBA Stats Website - [Link](\"https://www.nba.com/stats/players/traditional?PerMode=PerGame\")\n",
    "\n",
    "API Data:\n",
    "\n",
    "The data of the API was structured as JSON responses and contained data like this i.e.:\n",
    "\n",
    "![API Data](./images/APIData.png)\n",
    "\n",
    "This was our main data source, since the API tracked and updated the data very regularly and had most of the data we wanted in an already well-formatted structure, which was easy to use and clean. We simply sent requests for all the players that played in the specific prime years of the three players that are in focus and processed the responses.\n",
    "\n",
    "WebScraping:\n",
    "\n",
    "Our second data source was the official website nba.com/stats. To gather the data from this website we used WebScraping. The website looked like this:\n",
    "\n",
    "![Website Data](./images/nbaStatsWebsite.png)\n",
    "\n",
    "\n",
    "CSV Dataset:\n",
    "\n",
    "Our third and last data source was a CSV-file which was available on the popular Data Science website Kaggle. Here we simply picked a CSV-dataset which had the most complete amount of data and some additional stats that were missing from the other two sources. The data inside the file looked like this:\n",
    "\n",
    "![CSV Data](./images/CSVData.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Kafka Integration\n",
    "\n",
    "![Kafka](./images/Kafka.jpg)\n",
    "\n",
    "![Kafka Workflow]()\n",
    "\n",
    "In our project, we leveraged Kafka as a central data broker to streamline the handling of data from various sources. Specifically, we utilized Kafka to efficiently manage the API data and the data obtained through web scraping. By employing Kafka as the backbone of our data pipeline, we were able to establish a scalable and fault-tolerant architecture that facilitated the seamless flow of data throughout our project.\n",
    "\n",
    "To organize the data flow, we created two Kafka topics: one for the API data and another for the web scraping data. The topics served as logical channels where the data producers could publish the relevant information. This allowed us to decouple the data sources from the consumers, enabling asynchronous processing and ensuring data availability for downstream tasks.\n",
    "\n",
    "For pushing data to the Kafka topics, we implemented Kafka producers. These producers were responsible for fetching data from the respective sources and publishing it to the relevant topics in JSON format. In the case of the API data, we utilized the Kafka producer to consume the data from the API endpoints and push it to the corresponding Kafka topic. Similarly, for web scraping, we employed a Kafka producer to retrieve the scraped data, save them in CSV files, read them in and then publish it to the designated topic. This approach enabled us to collect and consolidate the data from multiple sources in a standardized and efficient manner.\n",
    "\n",
    "Here you can see the two Kafka Producers we wrote:\n",
    "\n",
    "- API Data Producer - [Notebook Path](../Kafka%20API%20PubSub/NBA%20API%20Producer.ipynb)\n",
    "\n",
    "- WebScraping Data Producer - [Notebook Path](../WebScraper/NBA%20WEB%20Producer.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "\n",
    "Since we took the ETL approach, we consumed or read the static data, cleaned our data and then uploaded it to our database.\n",
    "\n",
    "To view the individual Data Cleaning processes we linked the notebooks responsible for that here:\n",
    "\n",
    "- API Data Consuming & Cleaning - [Notebook Path](../Kafka%20API%20PubSub/API%20Data%20Consumer%20with%20Spark.ipynb)\n",
    "- Web Data Consuming & Cleaning - [Notebook Path](../WebScraper/NBA%20WEB%20Consumer.ipynb)\n",
    "- CSV Data Reading & Cleaning - [Notebook Path](../CSV%20Data/CSV-Script.ipynb)\n",
    "\n",
    "![SparkPandas](./images/SparkPandas.png)\n",
    "\n",
    "In the case of the API Data we consumed the data via Spark directly from Kafka and read it into a Spark Dataframe. For the WebScraping Data we simply read the Data into a Pandas Dataframe,created a Spark Dataframe out of it. For the static CSV Data from Kaggle we simply read the data, cleaned and uploaded it to MongoDB. In general we used different methods but most commonly we used Spark Dataframes versatile capabilities and also Pandas sometimes as an inbetween step. Most of the work we had to do was changing types specifically of the CSV Data, or certain values that had to be converted into numeric values specifically such as the statistic \"Minutes Played\" which was mostly in a string form like this \"30:26\". We also checked for Null values and duplicate data, but all in all this was very comfortable to do with the power and flexibility of Spark. One of the challenges we faced was figuring out which Year or Season was actually contained in the data, because some datasets had different meanings for a value like \"1995\", i.e. in one dataset that meant the season 1994-1995 and in the other it meant 1995-1996. In these instances we had to do some research and use our own domain knowledge to correctly address these issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETL Output\n",
    "\n",
    "![ETL](./images/ETL.png)\n",
    "\n",
    "After the data was extracted and transformed, we decided to store the analyzed and transformed data in MongoDB, a popular NoSQL database. MongoDB provided us with flexibility and scalability, allowing us to easily handle and query large volumes of data. We created three separate collections within MongoDB to store the different types of data: one for the API data, one for the web scraping data, and another for the CSV data obtained from Kaggle.\n",
    "\n",
    "![MongoDB](./images/mongoDB.png)\n",
    "![MongoCollections](./images/MongoCollections.png)\n",
    "![CleanData](./images/CleanData.png)\n",
    "\n",
    "To interact with MongoDB, we utilized the PyMongo library, which provided us with a Python interface to connect to the MongoDB database and perform operations. PyMongo allowed us to seamlessly insert the transformed data into the respective collections.\n",
    "\n",
    "![PyMongo](./images/PyMongo.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Analysis with Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "from pyspark import SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Spark Session using Mongo Spark Connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"NBA Analysis\") \\\n",
    "    .config(\"spark.mongodb.input.uri\", \"mongodb://pt-n20.p4001.w3.cs.technikum-wien.at:4001/nba_data.season_stats_web\") \\\n",
    "    .config(\"spark.mongodb.input.partitioner\", \"MongoSinglePartitioner\") \\\n",
    "    .config(\"spark.mongodb.input.partitionerOptions.partitionKey\", \"_id\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.mongodb.spark:mongo-spark-connector_2.12:3.0.1\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from MongoDB Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_web = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").load()\n",
    "df_api = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb://pt-n20.p4001.w3.cs.technikum-wien.at:4001/nba_data.season_stats_api\").load()\n",
    "df_csv = spark.read.format(\"com.mongodb.spark.sql.DefaultSource\").option(\"uri\", \"mongodb://pt-n20.p4001.w3.cs.technikum-wien.at:4001/nba_data.season_stats_csv\").load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Collections based on Player Name and Season Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_web = df_web.withColumnRenamed('SEASON', 'web_season')\n",
    "df_api = df_api.withColumnRenamed('season', 'api_season')\n",
    "joined_df = df_web.join(df_api, (df_web[\"PLAYER_NAME\"] == df_api[\"full_name\"]) & (df_web[\"web_season\"] == df_api[\"api_season\"]))\n",
    "joined_df = joined_df.join(df_csv, (joined_df[\"PLAYER_NAME\"] == df_csv[\"Full_Name\"]) & (joined_df[\"web_season\"] == df_csv[\"Season\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = [\"_id\",\"web_season\",\"Full_Name\",\"csv_season\",\"api_season\"]\n",
    "filtered_df = joined_df.drop(*columns_to_exclude)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation and Analysis\n",
    "\n",
    "Now that we have collected and processed the data, it's time to derive insights and draw meaningful conclusions. By leveraging visualizations and analysis techniques, we can uncover patterns, trends, and comparisons to gain a deeper understanding of the players' performances during the specified periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Spark Dataframe to Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_stats_df = filtered_df.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Context\n",
    "\n",
    "To truly analyze the impact and value of a player, it is extremely challenging to rely solely on numbers. Basketball, like any sport, involves intangible factors that can greatly contribute to a player's performance and overall impact. However, certain statistical categories can provide valuable insights into a player's skills and effectiveness on the court. In this analysis, we will focus on key categories that can help us understand why the three players excelled during these specific years. We will first look at how they performed individually compared to the league and in the second part compare the three players specifically and measure their overall impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Impact\n",
    "\n",
    "For the first part of the analysis the selected key categories are as follows:\n",
    "\n",
    "- Points (PTS)\n",
    "- Assists (AST)\n",
    "- Rebounds (REB)\n",
    "- Steals (STL)\n",
    "- Blocks (BLK)\n",
    "- Effective Field Goal Percentage (eFG%)\n",
    "- True Shooting Percentage (TS%)\n",
    "\n",
    "By examining these categories, we aim to gain insights into the exceptional individual performances during the players' prime periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hier kommt Marias MJ Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hier kommt Raads Kobe Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Black Mamba: Kobe Bryant\n",
    "\n",
    "Kobe Bryant, one of the greatest basketball players of all time, dominated the NBA during his prime years from 2005 to 2007. Known for his incredible scoring ability and relentless competitiveness, Bryant's performances during this period were nothing short of legendary. As we analyze his stats and compare them to the league's season averages, we gain deeper insights into his extraordinary impact on the game. \n",
    "\n",
    "Key Achievements during his prime:\n",
    "\n",
    "- NBA Most Valuable Player (2007-2008)\n",
    "- NBA All-Star (2005-2006, 2006-2007, 2007-2008)\n",
    "- NBA All-Star Game MVP (2006-2007)\n",
    "- All-NBA First Team (2005-2006, 2006-2007, 2007-2008)\n",
    "- NBA scoring champion (2005-2006, 2006-2007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "\n",
    "Before we start to analyse we need to define the dataframes containing the season stats of those individual years in which Kobe was at his peak. To do to that we use following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prime_2005_2007_df = nba_stats_df[nba_stats_df['Season'].isin([2005, 2006, 2007])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobe_prime_stats_df = prime_2005_2007_df[prime_2005_2007_df['PLAYER_NAME'] == 'Kobe Bryant']\n",
    "kobe_prime_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_averages_2005_2007_df = prime_2005_2007_df.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Points\n",
    "\n",
    "In this section, we will analyze the points scored by players during the 2005-2007 NBA seasons. Specifically, we will focus on comparing Kobe Bryant's scoring performance to that of the league as a whole:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the boxplot\n",
    "plt.boxplot(prime_2005_2007_df['pts'], vert=False)\n",
    "\n",
    "# Plot Kobe Bryant's stats as red markers\n",
    "kobe_points = kobe_prime_stats_df['pts']\n",
    "for point in kobe_points:\n",
    "    plt.plot(point, 1, 'ro')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Boxplot of Points in the 2005-2007 NBA Seasons')\n",
    "plt.xlabel('Points')\n",
    "plt.ylabel('Season')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summaries for 'pts' column in both DataFrames\n",
    "summary_league = prime_2005_2007_df['pts'].describe()\n",
    "summary_kobe = kobe_prime_stats_df['pts'].describe()\n",
    "\n",
    "# Concatenate the summaries horizontally\n",
    "summary_df = pd.concat([summary_league, summary_kobe], axis=1)\n",
    "summary_df.columns = ['League', 'Kobe Bryant']\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis of Kobe Bryant's scoring during the 2005-2007 NBA seasons reveals interesting insights:\n",
    "\n",
    "- Outstanding Scoring Ability: Kobe Bryant demonstrated exceptional scoring ability, as indicated by his average of 31.76 points per game. This places him significantly above the league average of 8.09 points per game.\n",
    "\n",
    "- Consistency and High Performance: Kobe's scoring performance consistently exceeded the league average. His lowest scoring season during his prime he averaged around 28.33 points, which is still significantly higher than the average. This consistency in high-scoring performances is remarkable.\n",
    "\n",
    "- Outlier Performances: The three red markers representing Kobe's points in the boxplot indicate that he achieved outstanding scoring performances during these specific seasons. With averages of approximately 28.33, 32, and 35.4 points, Kobe's ability to deliver exceptional scoring performances is evident.\n",
    "\n",
    "His performances consistently exceeded not only the league average but also other great players' averages, and he had multiple standout scoring seasons where he displayed his dominance and impact on the court."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assists\n",
    "\n",
    "When analyzing Kobe Bryant's assists during the 2005-2007 NBA seasons, it is essential to consider his position as a shooting guard (SG). While traditionally point guards are primarily responsible for playmaking and distributing the ball, examining assists for shooting guards can provide valuable insights into their role and impact on the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(prime_2005_2007_df['ast'], vert=False)\n",
    "\n",
    "# Plot Kobe Bryant's assists as red markers\n",
    "kobe_assists = kobe_prime_stats_df['ast']\n",
    "\n",
    "for assist in kobe_assists:\n",
    "    plt.plot(assist, 1, 'ro')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Boxplot of Assists in the 2005-2007 NBA Seasons (Shooting Guards)')\n",
    "plt.xlabel('Assists')\n",
    "plt.ylabel('Season')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_league = prime_2005_2007_df['ast'].describe()\n",
    "summary_kobe = kobe_prime_stats_df['ast'].describe()\n",
    "\n",
    "# Concatenate the summaries horizontally\n",
    "summary_df = pd.concat([summary_league, summary_kobe], axis=1)\n",
    "summary_df.columns = ['League', 'Kobe Bryant']\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the boxplot, we observe that Kobe Bryant's assist numbers are generally higher than the league average, positioning him as an outlier. The summary statistics indicate that Kobe Bryant averaged 5.08 assists per game which places him above the league average of 1.76 assists, showcasing his exceptional playmaking skills. This consistency in his assists highlights his ability to consistently contribute to his team's offense despite not playing as a point guard."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rebounds\n",
    "\n",
    "Examining Kobe Bryant's rebounding performance during the 2005-2007 NBA seasons provides insights into his versatility and ability to contribute beyond his primary role as a shooting guard. Despite being 198cm tall, which is relatively average for a shooting guard, he was very athletic. Did that help him? Let us find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the DataFrame for shooting guards\n",
    "shooting_guards_df = prime_2005_2007_df[prime_2005_2007_df['Pos'] == 'SG']\n",
    "\n",
    "# Calculate the league average rebounds for shooting guards\n",
    "league_avg_rebounds_sg = shooting_guards_df['reb'].mean()\n",
    "\n",
    "# Calculate the league average rebounds for each season\n",
    "league_avg_rebounds_2005 = prime_2005_2007_df[prime_2005_2007_df['Season'] == 2005]['reb'].mean()\n",
    "league_avg_rebounds_2006 = prime_2005_2007_df[prime_2005_2007_df['Season'] == 2006]['reb'].mean()\n",
    "league_avg_rebounds_2007 = prime_2005_2007_df[prime_2005_2007_df['Season'] == 2007]['reb'].mean()\n",
    "\n",
    "# Plot the league average rebounds for shooting guards as three distinct points\n",
    "plt.plot([2005, 2006, 2007], [league_avg_rebounds_2005, league_avg_rebounds_2006, league_avg_rebounds_2007],\n",
    "         color='blue', marker='o', linestyle='--', label='League Average (SG)')\n",
    "\n",
    "# Plot Kobe Bryant's rebounds as a line graph\n",
    "kobe_rebounds = kobe_prime_stats_df['reb']\n",
    "seasons = kobe_rebounds.index\n",
    "\n",
    "plt.plot([2005, 2006, 2007], kobe_rebounds, color='red', marker='o', label='Kobe Bryant (SG)')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Rebounds in the 2005-2007 NBA Seasons (Shooting Guards)')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Rebounds')\n",
    "plt.legend()\n",
    "\n",
    "# Set the x-axis tick positions and labels\n",
    "plt.xticks([2005, 2006, 2007], ['2005', '2006', '2007'])\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_league = prime_2005_2007_df['reb'].describe()\n",
    "summary_kobe = kobe_prime_stats_df['reb'].describe()\n",
    "\n",
    "# Concatenate the summaries horizontally\n",
    "summary_df = pd.concat([summary_league, summary_kobe], axis=1)\n",
    "summary_df.columns = ['League', 'Kobe Bryant']\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kobe Bryant's rebounding performance as a shooting guard during the 2005-2007 NBA seasons was exceptional. With an average of 5.77 rebounds per game, Kobe consistently outperformed the league average of 3.52 rebounds per game for shooting guards. Standing at 198cm tall, Kobe's ability to secure rebounds demonstrated his versatility and determination on the court. His rebounding prowess added to his all-around impact on the game, showcasing his ability to contribute in multiple facets beyond scoring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steals\n",
    "\n",
    "Kobe was generally considered a two-way player meaning that he was good both on offence and defence, but do the stats mirror this view of him? Let us find out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "league_steals_2005_2007 = prime_2005_2007_df.groupby('PLAYER_NAME')['stl'].mean()\n",
    "\n",
    "# Sort the data by steals per game in descending order\n",
    "sorted_steals = league_steals_2005_2007.sort_values(ascending=False)\n",
    "\n",
    "# Determine the position of Kobe Bryant in the sorted list\n",
    "kobe_position = sorted_steals.index.get_loc('Kobe Bryant')\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_steals)), sorted_steals, color='blue')\n",
    "plt.axhline(y=sorted_steals.iloc[kobe_position], color='red', linestyle='--', label='Kobe Bryant')\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Steals in the 2005-2007 NBA Seasons')\n",
    "plt.xlabel('Player')\n",
    "plt.ylabel('Steals per Game')\n",
    "\n",
    "# Label Kobe Bryant's position\n",
    "plt.text(kobe_position, sorted_steals.iloc[kobe_position], 'Kobe Bryant', ha='center', va='bottom')\n",
    "\n",
    "# Remove the player labels at the bottom\n",
    "plt.xticks([])\n",
    "\n",
    "# Show the chart\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_league = prime_2005_2007_df['stl'].describe()\n",
    "summary_kobe = kobe_prime_stats_df['stl'].describe()\n",
    "\n",
    "# Concatenate the summaries horizontally\n",
    "summary_df = pd.concat([summary_league, summary_kobe], axis=1)\n",
    "summary_df.columns = ['League', 'Kobe Bryant']\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numbers and the graphs reflect his ability to make impactful defensive plays and contribute to the team's overall defensive efforts.\n",
    "\n",
    "Comparatively, the league average for steals during the same period was 0.61 steals per game. Kobe's steal averages significantly exceed the league average, indicating his proficiency in disrupting opponents' offensive plays and showcasing his defensive prowess.\n",
    "\n",
    "These statistics support the notion that Kobe Bryant was indeed a formidable defensive player in addition to his offensive skills. His ability to consistently contribute steals demonstrates his active presence on the defensive end and highlights his commitment to being a well-rounded player."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blocks\n",
    "\n",
    "Since shorter players and positions like guards usually are not protecting the basketball rim, they block less shots. For this reason we will compare Kobe's blocks stats between him and other shooting guards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for shooting guards in the league\n",
    "shooting_guards_df = nba_stats_df[nba_stats_df['Pos'] == 'SG']\n",
    "\n",
    "# Calculate the blocks per game for shooting guards\n",
    "shooting_guard_blocks = shooting_guards_df.groupby('PLAYER_NAME')['blk'].mean()\n",
    "\n",
    "# Sort the data by blocks per game in descending order\n",
    "sorted_blocks = shooting_guard_blocks.sort_values(ascending=False)\n",
    "\n",
    "# Determine the position of Kobe Bryant in the sorted list\n",
    "kobe_position = sorted_blocks.index.get_loc('Kobe Bryant')\n",
    "\n",
    "# Create the bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(sorted_blocks)), sorted_blocks, color='blue')\n",
    "plt.axhline(y=sorted_blocks.iloc[kobe_position], color='red', linestyle='--', label='Kobe Bryant')\n",
    "\n",
    "# Set the title and axis labels\n",
    "plt.title('Blocks per Game in the 2005-2007 NBA Seasons')\n",
    "plt.xlabel('Player')\n",
    "plt.ylabel('Blocks per Game')\n",
    "\n",
    "# Label Kobe Bryant's position\n",
    "plt.text(kobe_position, sorted_blocks.iloc[kobe_position], 'Kobe Bryant', ha='center', va='bottom')\n",
    "\n",
    "# Remove the player labels at the bottom\n",
    "plt.xticks([])\n",
    "\n",
    "# Show the chart\n",
    "plt.tight_layout()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_league = prime_2005_2007_df['blk'].describe()\n",
    "summary_kobe = kobe_prime_stats_df['blk'].describe()\n",
    "\n",
    "# Concatenate the summaries horizontally\n",
    "summary_df = pd.concat([summary_league, summary_kobe], axis=1)\n",
    "summary_df.columns = ['League', 'Kobe Bryant']\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the data Kobe had an average of 0.446 blocks per game during the 2005-2007 NBA seasons. Comparing this to the league average for shooting guards, which was 0.393 blocks per game, we can see that Kobe performed slightly above the average for players in his position.\n",
    "\n",
    "The statistics also indicate that Kobe's blocks per game were relatively consistent, with a minimum of 0.380 blocks and a maximum of 0.490 blocks. Additionally, his blocks per game fell within the interquartile range of 0.425 to 0.480, suggesting a consistent performance compared to other shooting guards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Effective Field Goal Percentage\n",
    "\n",
    "Effective Field Goal Percentage (eFG%) is a metric that adjusts the traditional field goal percentage to account for the added value of made 3-point field goals. By giving 3-pointers 1.5 times the weight of 2-pointers, eFG% provides a more accurate measure of a player's shooting efficiency. In comparing Kobe Bryant's eFG% to the league average, we can assess his effectiveness as a scorer in terms of maximizing the value of his field goal attempts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobe_efg_avg = kobe_prime_stats_df.groupby('Season')['eFG%'].mean()\n",
    "league_avg_efg = nba_stats_df['eFG%'].mean()\n",
    "\n",
    "plt.bar(kobe_efg_avg.index, kobe_efg_avg, color='red', label='Kobe Bryant')\n",
    "plt.axhline(league_avg_efg, color='blue', linestyle='--', label='League Average')\n",
    "\n",
    "plt.title('Effective Field Goal Percentage: Kobe Bryant vs League Average')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('Effective Field Goal Percentage (eFG%)')\n",
    "\n",
    "plt.xticks([2005, 2006, 2007], ['2005', '2006', '2007'])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_league = prime_2005_2007_df['eFG%'].describe()\n",
    "summary_kobe = kobe_prime_stats_df['eFG%'].describe()\n",
    "\n",
    "# Concatenate the summaries horizontally\n",
    "summary_df = pd.concat([summary_league, summary_kobe], axis=1)\n",
    "summary_df.columns = ['League', 'Kobe Bryant']\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kobe had an average effective field goal percentage (eFG%) of 0.499, which is higher than the league average of 0.471. This suggests that Kobe was an efficient scorer, as he was able to maximize the value of his field goal attempts by shooting at a higher percentage than the league average.\n",
    "\n",
    "Throughout the three seasons in his prime he consistenly scored more efficiently than the league average which is not easy to do and explains further as to why he was such a great offensive weapon."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### True Shooting Percentage\n",
    "\n",
    "True Shooting Percentage (TS%) is a comprehensive measure that incorporates the value of three-pointers and free throws, along with two-point field goals, to provide a holistic view of a player's scoring efficiency. By considering the scoring impact of different shot types, TS% offers a more complete assessment of Kobe's ability to maximize his scoring opportunities compared to the league average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kobe_ts_avg = kobe_prime_stats_df.groupby('Season')['TS%'].mean()\n",
    "league_avg_ts = nba_stats_df['TS%'].mean()\n",
    "\n",
    "plt.bar(kobe_ts_avg.index, kobe_ts_avg, color='red', label='Kobe Bryant')\n",
    "plt.axhline(league_avg_ts, color='blue', linestyle='--', label='League Average')\n",
    "\n",
    "plt.title('True Shooting Percentage: Kobe Bryant vs League Average')\n",
    "plt.xlabel('Season')\n",
    "plt.ylabel('True Shooting Percentage (TS%)')\n",
    "\n",
    "plt.xticks([2005, 2006, 2007], ['2005', '2006', '2007'])\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_league = prime_2005_2007_df['TS%'].describe()\n",
    "summary_kobe = kobe_prime_stats_df['TS%'].describe()\n",
    "\n",
    "# Concatenate the summaries horizontally\n",
    "summary_df = pd.concat([summary_league, summary_kobe], axis=1)\n",
    "summary_df.columns = ['League', 'Kobe Bryant']\n",
    "\n",
    "# Print the summary DataFrame\n",
    "print(summary_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kobe's True Shooting Percentage (TS%) of 0.57 exceeds the league average of 0.51. This indicates that Kobe was highly efficient in scoring, as he consistently outperformed the average player (by at least 4%-7%) in terms of maximizing his scoring opportunities across various shot types, including three-pointers, two-pointers, and free throws. This statistic really seperated Kobe from the rest of the league and signifies his true efficiency during those prime years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hier kommt Kevins LeBron Analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Overall Impact\n",
    "\n",
    "Now that we have taken a look at the players' individual statistics it comes down to the analysis of their overall impact to really determine who is the greatest of them all statistically. To help us with this we look at these key categories, which measure to a certain extent how much the three players in focus made their team better:\n",
    "\n",
    "- Team Wins (W)\n",
    "- Defensive Win Shares (DWS)\n",
    "- Offensive Win Shares (OWS)\n",
    "- Win Shares (WS)\n",
    "- Player Efficiency Rating (PER) and Plus-Minus (+/-)\n",
    "\n",
    "By looking at these numbers we will get a clearer picture and decide once and for all who was the best at their best!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hier kommt Team Wins und Defensive Win Shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hier kommt Offensive Win Shares und Shares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Player Efficiency Rating and Plus-Minus\n",
    "\n",
    "These two statistics are defined as:\n",
    "\n",
    "- Player Efficiency Rating (PER): The Player Efficiency Rating (PER) is a per-minute rating developed by ESPN.com columnist John Hollinger. In John's words, \"The PER sums up all a player's positive accomplishments, subtracts the negative accomplishments, and returns a per-minute rating of a player's performance.\"\n",
    "- Plus Minus (+/-): The point differential when a player or team is on the floor\n",
    "\n",
    "Sources: [Link](https://www.basketball-reference.com/about/per.html) & [Link](https://www.nba.com/stats/help/glossary)\n",
    "\n",
    "By examining the combined Player Efficiency Ratings (PER) and Plus-Minus (+/-) statistics of Michael Jordan, Kobe Bryant, and LeBron James during their prime years, we can gain valuable insights into their overall impact and effectiveness on the basketball court. These metrics provide a comprehensive measure of their individual contributions to team performance and success."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mj_prime_stats_df['PLUS_MINUS'], mj_prime_stats_df['PER'], color='red', label='Michael Jordan')\n",
    "plt.scatter(kobe_prime_stats_df['PLUS_MINUS'], kobe_prime_stats_df['PER'], color='purple', label='Kobe Bryant')\n",
    "plt.scatter(lebron_prime_stats_df['PLUS_MINUS'], lebron_prime_stats_df['PER'], color='blue', label='LeBron James')\n",
    "\n",
    "# Set the title and labels\n",
    "plt.title('Plus-Minus (+/-) and Player Efficiency Rating (PER)')\n",
    "plt.xlabel('Plus-Minus (+/-)')\n",
    "plt.ylabel('Player Efficiency Rating (PER)')\n",
    "\n",
    "# Add a smaller legend\n",
    "plt.legend(fontsize='small')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the combined correlation of these two numbers we see that LeBron seems to completely outshine Michael Jordan and Kobe Bryant, when it comes to overall positive impact on the court. The pattern indicates following ranking based purely on these two statistical metrics of their prime years:\n",
    "\n",
    "1. LeBron James\n",
    "2. Michael Jordan\n",
    "3. Kobe Bryant\n",
    "\n",
    "We should note though that the season which is missing from Michaels prime years is the 1995-1996 season which is the historic 72-10 Chicago Bulls season, which Michael was the absolute center piece of. There is potentially some more insight that can be gained from that data, but overall this graphic seems to paint a decisive picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Take-Aways and Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
